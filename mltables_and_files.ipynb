{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook look how to manage MLTables locally and create yaml files for loading it on cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mlTable and .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob the parquet file paths for years 2015-19, all months.\n",
    "paths = [\n",
    "    {\n",
    "        \"pattern\": \"wasbs://nyctlc@azureopendatastorage.blob.core.windows.net/green/puYear=2015/puMonth=*/*.parquet\"\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"wasbs://nyctlc@azureopendatastorage.blob.core.windows.net/green/puYear=2016/puMonth=*/*.parquet\"\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"wasbs://nyctlc@azureopendatastorage.blob.core.windows.net/green/puYear=2017/puMonth=*/*.parquet\"\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"wasbs://nyctlc@azureopendatastorage.blob.core.windows.net/green/puYear=2018/puMonth=*/*.parquet\"\n",
    "    },\n",
    "    {\n",
    "        \"pattern\": \"wasbs://nyctlc@azureopendatastorage.blob.core.windows.net/green/puYear=2019/puMonth=*/*.parquet\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# create a table from the parquet paths\n",
    "tbl = mltable.from_parquet_files(paths)\n",
    "\n",
    "# table a random sample\n",
    "tbl = tbl.take_random_sample(probability=0.001, seed=735)\n",
    "\n",
    "# filter trips with a distance > 0\n",
    "tbl = tbl.filter(\"col('tripDistance') > 0\")\n",
    "\n",
    "# Drop columns\n",
    "tbl = tbl.drop_columns([\"puLocationId\", \"doLocationId\", \"storeAndFwdFlag\"])\n",
    "\n",
    "# Create two new columns - year and month - where the values are taken from the path\n",
    "tbl = tbl.extract_columns_from_partition_format(\"/puYear={year}/puMonth={month}\")\n",
    "\n",
    "# print the first 5 records of the table as a check\n",
    "tbl.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mlTable file in .nyc/taxi\n",
    "tbl.save(\"./nyc_taxi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = mltable.load(\"./nyc_taxi/\")\n",
    "table.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in pandas dataframe\n",
    "\n",
    "df = tbl.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell make the taxis.csv file in .nyc/taxi directory\n",
    "\n",
    "df.to_csv(\"./nyc_taxi/taxis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A visualization of dataframe columns distribution\n",
    "\n",
    "import seaborn as sns\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write .yml and .py files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./env/conda_dependencies.yml\n",
    "\n",
    "# ./env/conda_dependencies.yml\n",
    "dependencies:\n",
    "  - python=3.10\n",
    "  - pip=21.2.4\n",
    "  - pip:\n",
    "      - mltable\n",
    "      - azureml-dataprep[pandas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./src/load_data.py\n",
    "\n",
    "# ./src/load_data.py\n",
    "import argparse\n",
    "import mltable\n",
    "\n",
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input', help='mltable to read')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# load mltable\n",
    "tbl = mltable.load(args.input)\n",
    "\n",
    "# load into pandas\n",
    "df = tbl.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./src/move_data.py\n",
    "\n",
    "# ./src/move_data.py\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def main(args):\n",
    "    # read data\n",
    "    df = get_data(args.input_data)\n",
    "\n",
    "    output_df = df.to_csv((Path(args.output_datastore) / \"taxis.csv\"), index = False)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Count the rows and print the result\n",
    "    row_count = (len(df))\n",
    "    print('Analyzing {} rows of data'.format(row_count))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--input_data\", dest='input_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
    "                        type=str)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wanna execute job from azure cli, run this cell to make the .yml file\n",
    "\n",
    "%%writefile mltable-job.yml\n",
    "\n",
    "# mltable-job.yml\n",
    "$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json\n",
    "\n",
    "code: ./src\n",
    "\n",
    "command: python load_data.py --input ${{inputs.green}}\n",
    "inputs:\n",
    "    green:\n",
    "      type: mltable\n",
    "      path: azureml:ml_table_training:1\n",
    "\n",
    "compute: azureml:taxi-cluster\n",
    "\n",
    "environment:\n",
    "  image: mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\n",
    "  conda_file: ./env/conda_dependencies.yml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
